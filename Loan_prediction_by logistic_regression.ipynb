{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Information:\n",
    "The data set is based upon <a src=\"https://www.kaggle.com/prateikmahendra/loan-data\"> Lending Club Information </a>. \n",
    "- TheIrish Dummy Banks  is a  peer to peer lending bank based in the ireland, in which bank provide funds for potential borrowers and bank earn a profit depending on the risk they take (the borrowers credit score). Irish Fake bank provides loan to their loyal customers. The complete data set is borrowed from Lending Club For more basic information about the company please check out the wikipedia article about the company. This dataset is copied and clean from kaggle but it has been changed. The any kind of similarity is just for learning purposes. I dont have any intention for palgrisim I just like to be clear myself. <br><br>\n",
    "\n",
    "\n",
    "<a src=\"https://en.wikipedia.org/wiki/Lending_Club\"> Lending Club Information </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrferozi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import our libraries we are going to use for our data analysis.\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotly visualizations\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "# For oversampling Library (Dealing with Imbalanced Datasets)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from IPython.display import HTML\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/mrferozi/Documents/Panada_ml/loan/lending-club-loan-data/loan_final313.csv\",low_memory=False, index_col=0)\n",
    "\n",
    "# Copy of the dataframe\n",
    "original_df = df.copy()\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                      int64\n",
       "issue_d                  object\n",
       "final_d                   int64\n",
       "emp_length_int          float64\n",
       "home_ownership           object\n",
       "home_ownership_cat        int64\n",
       "income_category          object\n",
       "annual_inc                int64\n",
       "income_cat                int64\n",
       "loan_amount               int64\n",
       "term                     object\n",
       "term_cat                  int64\n",
       "application_type         object\n",
       "application_type_cat      int64\n",
       "purpose                  object\n",
       "purpose_cat               int64\n",
       "interest_payments        object\n",
       "interest_payment_cat      int64\n",
       "loan_condition           object\n",
       "loan_condition_cat        int64\n",
       "interest_rate           float64\n",
       "grade                    object\n",
       "grade_cat                 int64\n",
       "dti                     float64\n",
       "total_pymnt             float64\n",
       "total_rec_prncp         float64\n",
       "recoveries              float64\n",
       "installment             float64\n",
       "region                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "How do we choose which features to include in the model? We're going to use **train/test split** (and eventually **cross-validation**).\n",
    "\n",
    "Why not use of **p-values** or **R-squared** for feature selection?\n",
    "\n",
    "- Linear models rely upon **a lot of assumptions** (such as the features being independent), and if those assumptions are violated, p-values and R-squared are less reliable. Train/test split relies on fewer assumptions.\n",
    "- Features that are unrelated to the response can still have **significant p-values**.\n",
    "- Adding features to your model that are unrelated to the response will always **increase the R-squared value**, and adjusted R-squared does not sufficiently account for this.\n",
    "- p-values and R-squared are **proxies** for our goal of generalization, whereas train/test split and cross-validation attempt to **directly estimate** how well the model will generalize to out-of-sample data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models with train/test split and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of features\n",
    "feature_cols = ['emp_length_int', 'annual_inc','loan_amount',\n",
    "                'interest_rate','dti','home_ownership_cat',\n",
    "               'income_cat','total_pymnt','purpose_cat','grade_cat',\n",
    "               'application_type_cat','term_cat','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# define a function that accepts a list of features and returns testing RMSE\n",
    "def train_test_rmse(feature_cols):\n",
    "    X = df[feature_cols]\n",
    "    y = df.loan_condition_cat\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2602041769988056\n"
     ]
    }
   ],
   "source": [
    "# compare different sets of features\n",
    "print (train_test_rmse(['emp_length_int','annual_inc','loan_amount','interest_rate','dti','home_ownership_cat']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2508278160811187\n"
     ]
    }
   ],
   "source": [
    "print (train_test_rmse(['emp_length_int','annual_inc','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat','year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2583471389714144\n"
     ]
    }
   ],
   "source": [
    "print (train_test_rmse(['emp_length_int','annual_inc','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2508278160811187\n"
     ]
    }
   ],
   "source": [
    "print (train_test_rmse(['emp_length_int','annual_inc','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat','year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25127812204823347\n"
     ]
    }
   ],
   "source": [
    "print (train_test_rmse(['emp_length_int','annual_inc','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','term_cat','year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2508278160811187\n"
     ]
    }
   ],
   "source": [
    "print (train_test_rmse(['emp_length_int','annual_inc','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat','year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That is mean that all features have equal importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of features\n",
    "feature_cols = ['emp_length_int', 'annual_inc','loan_amount',\n",
    "                'interest_rate','dti','home_ownership_cat',\n",
    "               'income_cat','total_pymnt','purpose_cat','grade_cat',\n",
    "               'application_type_cat','term_cat','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_cols]\n",
    "y = df.loan_condition_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modeling process\n",
    "# spilt X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Logreg = LogisticRegression()\n",
    "Logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class prediction for the testing set\n",
    "y_pred_class = Logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Accuracy : percentage of correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.33518898329916\n"
     ]
    }
   ],
   "source": [
    "# calculate Accuracy\n",
    "from sklearn import metrics\n",
    "print((metrics.accuracy_score(y_test, y_pred_class))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null accuracy : accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204841\n",
       "1     17004\n",
       "Name: loan_condition_cat, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using panda series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- System Predict Good loan = 204841 and Bad Loan =  17004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0766481101670085"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.33518898329916\n"
     ]
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "print ((1- y_test.mean())*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9233518898329915\n"
     ]
    }
   ],
   "source": [
    "# claculate null accuracy ( for binary classification problem coded as 0/1)\n",
    "print (max(y_test.mean(), 1- y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing the true and predicted response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "from __future__ import print_function\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
